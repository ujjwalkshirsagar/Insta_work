{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a90fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.instagram.com/khwaaishh_vlogs/\n",
      "{\n",
      "  \"username\": \"khwaaishh_vlogs\",\n",
      "  \"business_category_name\": \"None\"\n",
      "}\n",
      "https://www.instagram.com/samruddhi/\n",
      "{\n",
      "  \"username\": \"samruddhi\",\n",
      "  \"business_category_name\": \"None\"\n",
      "}\n",
      "https://www.instagram.com/theguiderslife/\n",
      "{\n",
      "  \"username\": \"theguiderslife\",\n",
      "  \"business_category_name\": \"None\"\n",
      "}\n",
      "https://www.instagram.com/dapperlytamed/\n",
      "{\n",
      "  \"username\": \"dapperlytamed\",\n",
      "  \"business_category_name\": \"Creators & Celebrities\"\n",
      "}\n",
      "https://www.instagram.com/officialvidhiyadav/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "cookies = {\n",
    "    'mid': 'YROCfQALAAHAL0-Xxjc_bAAbFZOX',\n",
    "    'ig_did': '60430A35-BA2F-4E48-8443-4B48038F429F',\n",
    "    'ig_nrcb': '1',\n",
    "    'csrftoken': 'G0cQrTNLnV40ztKhhnJ8ic59iIcUL3TQ',\n",
    "    'ds_user_id': '48449422522',\n",
    "    'sessionid': '48449422522%3AVb6k3FE1h3vEQc%3A24',\n",
    "    'rur': 'CLN\\\\\\\\05448449422522\\\\\\\\0541660283979:01f72c4bff7ba665f34ceb0e3f553aa2a249fa8abdda7ad79f56068dc13486f0b3531c44',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0',\n",
    "    'Accept': '*/*',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.instagram.com/',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'TE': 'trailers',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('query_hash', 'ed2e3ff5ae8b96717476b62ef06ed8cc'),\n",
    "    ('variables', '{\"fetch_media_count\":0,\"fetch_suggested_count\":30,\"ignore_cache\":true,\"filter_followed_friends\":true,\"seen_ids\":[],\"include_reel\":true}'),\n",
    ")\n",
    "\n",
    "response = requests.get('https://www.instagram.com/graphql/query/', headers=headers, params=params, cookies=cookies)\n",
    "\n",
    "#NB. Original query string below. It seems impossible to parse and\n",
    "#reproduce query strings 100% accurately so the one below is given\n",
    "#in case the reproduced version is not \"correct\".\n",
    "# response = requests.get('https://www.instagram.com/graphql/query/?query_hash=ed2e3ff5ae8b96717476b62ef06ed8cc&variables=%7B%22fetch_media_count%22%3A0%2C%22fetch_suggested_count%22%3A30%2C%22ignore_cache%22%3Atrue%2C%22filter_followed_friends%22%3Atrue%2C%22seen_ids%22%3A%5B%5D%2C%22include_reel%22%3Atrue%7D', headers=headers, cookies=cookies)\n",
    "\n",
    "\n",
    "def csv_reader_list(file_name):\n",
    "    \n",
    "    list_l=[]\n",
    "    csv_file= open(file_name, 'r')\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader: \n",
    "        list_l.append(row)\n",
    "    csv_file.close()\n",
    "    return list_l\n",
    "\n",
    "\n",
    "def extract_json_objects(text, decoder=json.JSONDecoder()):\n",
    "\n",
    "    pos = 0\n",
    "    while True:\n",
    "        match = text.find('{', pos)\n",
    "        if match == -1:\n",
    "            break\n",
    "        try:\n",
    "            result, index = decoder.raw_decode(text[match:])\n",
    "            yield result\n",
    "            pos = match + index\n",
    "        except ValueError:\n",
    "            pos = match + 1\n",
    "            \n",
    "            \n",
    "            \n",
    "list_to_scrape = csv_reader_list(\"Rounding off 2.csv\") \n",
    "url=\"https://www.instagram.com/nishthaparwanda/\"\n",
    "\n",
    "dict_list = []  \n",
    "error_roposo = []   \n",
    "\n",
    "# html_content = requests.get(url,headers=headers, params=params, cookies=cookies).text\n",
    "# soup = BeautifulSoup(html_content,'html.parser')\n",
    "# data1=soup.find_all(\"script\", type=\"text/javascript\")[3]\n",
    "# listToStr = ' '.join([str(elem) for elem in data1])\n",
    "# data=listToStr[21:-1]\n",
    "\n",
    "\n",
    "for row in list_to_scrape:\n",
    "    try:\n",
    "        url = ' '.join(map(str, row))\n",
    "        print(url)\n",
    "        html_content = requests.get(url,headers=headers, params=params, cookies=cookies).text\n",
    "        soup = BeautifulSoup(html_content,'html.parser')\n",
    "        data1=soup.find_all(\"script\", type=\"text/javascript\")[3]\n",
    "        listToStr = ' '.join([str(elem) for elem in data1])\n",
    "        data=listToStr[21:-1]\n",
    "        y = json.loads(data)\n",
    "\n",
    "    #     print(y[\"entry_data\"][\"ProfilePage\"][0][\"graphql\"]['user'])\n",
    "    #     print(data)\n",
    "\n",
    "        dict1 = {}\n",
    "        dict_publishers=y[\"entry_data\"][\"ProfilePage\"][0][\"graphql\"]['user']\n",
    "        keys =[\"username\",\"business_category_name\"]\n",
    "        dict1 = {x:str(dict_publishers[x]).replace('\\n',' || ') for x in keys}\n",
    "        #dict1[\"link\"] = url\n",
    "        print(json.dumps(dict1,indent=2)) \n",
    "        dict_list.append(dict1)\n",
    "        #listD.append(url)\n",
    "    except:\n",
    "        print(\"Profile not found\")\n",
    "        continue\n",
    "    \n",
    "uk=[]\n",
    "print(len(dict_list))\n",
    "i=0\n",
    "if len(dict_list)!=0:\n",
    "    \n",
    "    for u in dict_list:\n",
    "        i==0\n",
    "        keys_values = dict_list[i].items()\n",
    "        new_d = {str(key): str(value) for key, value in keys_values}\n",
    "        i+=1\n",
    "        \n",
    "        uk.append(new_d)\n",
    "else:\n",
    "    print(\"End of Program\")\n",
    " \n",
    "import pandas as pd  \n",
    "df = pd.DataFrame(uk) \n",
    "    \n",
    "# saving the dataframe \n",
    "df.to_csv('U2.csv')\n",
    "                              \n",
    "\n",
    "print(\"\\n ========================= END OF PROGRAM ========================= \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80661b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
